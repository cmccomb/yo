#!/usr/bin/env zsh

# `yo` - A command-line AI assistant
function yo() {

	######################################################################################################################
	### UTILITIES AND CONSTANTS ##########################################################################################
	######################################################################################################################

	# Custom search API key
	local GOOGLE_CSE_API_KEY="AIzaSyBBXNq-DX1ENgFAiGCzTawQtWmRMSbDljk"
	local GOOGLE_CSE_ID="003333935467370160898:f2ntsnftsjy"
	local GOOGLE_CSE_BASE_URL="https://customsearch.googleapis.com/customsearch/v1"

	# Maximum length of file content to extract
	local MAX_FILE_CONTENT_LENGTH=10000

	# Version
	local VERSION="0.1.0"

	# Symbol used to signal the end of one-off sessions
	local STOP_SYMBOL="✌️"

	# Define parameters for the task model
	local TASK_MODEL_USERNAME="bartowski"
	local TASK_MODEL_SERIES="Qwen2.5"
	local TASK_MODEL_FINETUNING="Instruct"
	local TASK_MODEL_SIZE="1.5B"
	local TASK_MODEL_QUANT="Q4_K_M"
	local TASK_MODEL_FILETYPE="gguf"

	# Define parameters for the casual model
	local CASUAL_MODEL_USERNAME="bartowski"
	local CASUAL_MODEL_SERIES="Qwen2.5"
	local CASUAL_MODEL_FINETUNING="Instruct"
	local CASUAL_MODEL_SIZE="3B"
	local CASUAL_MODEL_QUANT="Q4_K_M"
	local CASUAL_MODEL_FILETYPE="gguf"

	# Define the series model parameters
	local SERIOUS_MODEL_USERNAME="bartowski"
	local SERIOUS_MODEL_SERIES="Qwen2.5"
	local SERIOUS_MODEL_FINETUNING="Instruct"
	local SERIOUS_MODEL_SIZE="14B"
	local SERIOUS_MODEL_QUANT="IQ4_XS"
	local SERIOUS_MODEL_FILETYPE="gguf"

	# Display version information
	function show_version() {
		echo "yo v$VERSION $STOP_SYMBOL"
	}

	# Display usage instructions
	function show_help() {
		cat <<-EOF
			yo - A command-line AI assistant.

			Usage:
			  yo [options] [question]

			Description:
			  If a question is provided, Yo will answer the question. Otherwise, Yo will enter an interactive session.

			Context Options:
			  These options help you control the information that Yo uses to answer your question.
			  -r, --read "PATH"       Extract information from the specified file or URL and integrate the results into Yo's
			                          context. Supports text-based files (e.g., .txt, .md, .py, etc.), PDF files via
			                          pdftotext, and web pages via curl and pandoc.
			  -s, --search "TERMS"    Perform a web search using the specified quoted terms and integrate the results into
			                          Yo's context. Requires an active internet connection.
			  -S, --surf              Perform a web search using LLM-chosen terms based on the question. Integrates results
			                          into Yo's context. Requires an active internet connection.
			  -y, --system            Perform several system commands and integrate the information into Yo's context.

			General Purpose Options:
			  These options provide general functionality.
			  -h, --help              Show this help message and exit.
			  -v, --verbose           Enable verbose mode for detailed output.
			  -V, --version           Show the version and exit.

			Examples:
			  1. Answer a question:
			    $ yo "What is the capital of France?"

			  2. For simple cases, you can omit the quotes:
			    $ yo what is the capital of france

			  3. Start an interactive session:
			    $ yo

			  4. Integrate information from a file:
			    $ yo --read src "How can I improve this source code?"

			  5. Integrate information from a URL:
			    $ yo --read https://en.wikipedia.org/wiki/Paris "how big is paris"

			  6. Integrate Google search results:
			    $ yo --search "what is the capital of Tobago"

			  7. Use LLM-selected search terms:
			    $ yo --surf tell me about renewable energy trends.

			  8. Combine context sources:
			    $ yo --read src --search "what is the capital of france"

			  9. Add verbosity to any of these commands
			    $ yo what is the capital of france --verbose
		EOF
	}

	function compose_repo_name() {
		local username=$1
		local series=$2
		local size=$3
		local finetuning=$4
		local filetype=$5
		echo "${username}/${series}-${size}-${finetuning}-$(echo $filetype | tr '[:lower:]' '[:upper:]')"
	}

	function compose_model_name() {
		local series=$1
		local size=$2
		local finetuning=$3
		local quant=$4
		local filetype=$5
		echo "${series}-${size}-${finetuning}-${quant}.${filetype}"
	}

	######################################################################################################################
	### SEARCH ###########################################################################################################
	######################################################################################################################

	# Perform a web search with user-provided terms
	function perform_search() {
		# Parse arguments
		local terms=$1

		# Make variables
		local url search_term_slug response

		# Generate search URL
		search_term_slug="${terms// /%20}"

		# Example API call
		url="$GOOGLE_CSE_BASE_URL?key=$GOOGLE_CSE_API_KEY&cx=$GOOGLE_CSE_ID&q=$search_term_slug"

		# Perform search and extract relevant information
		response=$(curl -s "$url" | grep -E "^      \"title\"|^      \"snippet\"")

		# Return response
		echo "$response"
	}

	# Extract optimized search terms using a small model
	function extract_search_terms() {

		# Parse arguments
		local query=$1 verbose=$2

		# Generate prompt
		local prompt=""
		prompt+="Your task is to extract the most relevant search terms from the following query for a web search.\n\n"
		prompt+="Here is an example:\n"
		prompt+="User Query: how large is the capital of france $STOP_SYMBOL\n"
		prompt+="Search Terms: paris capital population area\n\n"
		prompt+="Here is another:\n"
		prompt+="User Query: what is the furthest planet from the sun $STOP_SYMBOL\n"
		prompt+="Search Terms: solar system furthest planet distance\n\n"
		prompt+="Here is the real one.\n"
		prompt+="User Query: $query\n"
		prompt+="Search Terms: "

    # Generate response
    repo_name="$(compose_repo_name $TASK_MODEL_USERNAME $TASK_MODEL_SERIES $TASK_MODEL_SIZE $TASK_MODEL_FINETUNING $TASK_MODEL_FILETYPE)"
    model_name="$(compose_model_name $TASK_MODEL_SERIES $TASK_MODEL_SIZE $TASK_MODEL_FINETUNING $TASK_MODEL_QUANT $TASK_MODEL_FILETYPE)"

		# Generate response
		local terms
		terms=$(start_llama_session "$repo_name" "$model_name" "$prompt" false $verbose false 8)

		# Only take the first line
		terms=$(echo "$terms" | head -n 1)

		# Remove end of text if needed
		terms="${terms//\[end of text\]/}"

		# Return results
		echo "$terms"
	}

	######################################################################################################################
	### CONTENT EXTRACTION ###############################################################################################
	######################################################################################################################

	# Extract file_info from a file or URL (supports text and PDF files)
	function extract_file_info() {

		# Parse arguments
		local source=$1 max_length=$2

		# Make variables
		local file_info

		if [[ $source =~ ^https?:// ]]; then
			# Fetch file_info from URL
			if ! file_info=$(curl -s "$source" | pandoc -f html -t plain --quiet); then
				echo "Error: Failed to fetch file_info from URL." >&2
				return 1
			fi
		else
			# Fetch file_info from file
			[[ ! -f "$source" ]] && {
				echo "Error: File not found." >&2
				return 1
			}

			case $source in
			*.pdf)
				command -v pdftotext >/dev/null 2>&1 || {
					echo "Error: pdftotext not installed. Install it using your package manager (e.g., brew install poppler)." >&2
					return 1
				}
				file_info=$(pdftotext "$source" - 2>/dev/null)
				;;
			*.txt | *)
				file_info=$(cat "$source")
				;;
			esac
		fi

		# Trim to max length if needed
		[[ -n "$max_length" && "$max_length" -gt 0 ]] && file_info=${file_info:0:$max_length}

		# Return file_info
		echo "$file_info"
	}

	######################################################################################################################
	### LLMS AND PROMPTS #################################################################################################
	######################################################################################################################

	# Generate a prompt for one-off or interactive sessions
	function generate_prompt() {

		# Parse arguments
		local interactive=$1 file_info=$2 filename=$3 query=$4 search_info=$5 search_terms=$6 add_system_info=$7

		# Generate basic prompt
		local prompt=""
		prompt+="You are playing the role of Yo, a highly-capable AI assistant living in the MacOS terminal. "
		prompt+="It is currently $(date). "

		if [[ $add_system_info == true ]]; then
			prompt+="You were invoked from the $(pwd) directory "
			prompt+="on a $(system_profiler SPHardwareDataType | grep "Model Name" | awk -F": " '{print $2}') "
			prompt+="with $(sysctl -n hw.ncpu) cores, "
			prompt+="$(sysctl -n hw.memsize | awk '{x=$1/1024/1024/1024; print x}')GB RAM, "
			prompt+="and $(df -h / | tail -1 | awk '{split($4, a, "G"); print a[1]}')GB free disk space.\n\n"
		fi

		# Add file file_info if available
		if [[ -n "$file_info" ]]; then
			prompt+="Relevant information from this file: $filename:\n"
			prompt+="================= BEGINNING OF FILE CONTENTS =================\n"
			prompt+="$file_info\n"
			prompt+="==================== END OF FILE CONTENTS ====================\n\n"
		fi

		# Add search information if available
		if [[ -n "$search_terms" ]]; then
			prompt+="Relevant information from web search using these terms: $search_terms:\n"
			prompt+="================= BEGINNING OF SEARCH RESULTS =================\n"
			prompt+="$search_info\n"
			prompt+="==================== END OF SEARCH RESULTS ====================\n\n"
		fi

		# Add query and instructions based on interactive
		if [[ $interactive == false ]]; then
			prompt+="Your task is to directly answer the user's question. "
			prompt+="Your answer will be concise, helpful, and immediately usable. "
			prompt+="End your answer with the stop symbol $STOP_SYMBOL.\n\n"
			prompt+="User Query: $query $STOP_SYMBOL\n"
			prompt+="Your Super-Short Answer:"
		else
			prompt+="Your task is to assist the user in an interactive session, responding concisely and accurately."
		fi

		# Return prompt
		echo "$prompt"
	}

	# Start a llama-cli session
	function start_llama_session() {

		# Parse arguments
		local repo_name=$1 model_name=$2 prompt=$3 interactive=$4 squash_stderr=$5 display_prompt=$6 number_of_tokens_to_generate=$7

		# Configure llama-cli arguments
		local args=(
			--threads "$(sysctl -n hw.logicalcpu_max)"
			--hf-repo "$repo_name"
			--hf-file "$model_name"
			--prompt "$prompt"
			--prompt-cache "/tmp/yo_prompt_cache_$repo_name_$model_name"
			--predict "$number_of_tokens_to_generate"
			--temp 0.2
			--seed 42
			--flash-attn
			--prio 3
			--mirostat 2
		)

		# Add conversation or reverse-prompt based on mode
		if [[ $interactive == true ]]; then
			args+=(--conversation)
		else
			args+=(--reverse-prompt "$STOP_SYMBOL")
		fi

		# Display prompt
		if [[ $display_prompt != true ]]; then
			args+=(--no-display-prompt)
		else
			args+=(--verbose-prompt)
		fi

		# Start session
		if [[ $squash_stderr != true ]]; then
			llama-cli "${args[@]}" 2>/dev/null
		else
			llama-cli "${args[@]}"
		fi
	}

	######################################################################################################################
	### MAIN FUNCTION ####################################################################################################
	######################################################################################################################

	# Parse arguments
	local read_file="" query="" search_terms=""
	local read_mode=false add_system_info=false search_mode=false surf_mode=false verbose=false
	while [[ $# -gt 0 ]]; do
		case $1 in
		-h | --help)
			show_help
			return 0
			;;
		-r | --read)
			read_mode=true
			if [[ -n $2 && ! $2 =~ ^- ]]; then
				read_file=$2
				shift
			else
				echo "Error: --read requires a file." >&2
				return 1
			fi
			;;
		-v | --verbose) verbose=true ;;
		-V | --version)
			show_version
			return 0
			;;
		-s | --search)
			search_mode=true
			if [[ -n $2 && $2 =~ ^".*"$ ]]; then
				search_terms=$2
				shift
			else
				echo "Error: --search requires quoted terms." >&2
				return 1
			fi
			;;
		-S | --surf) surf_mode=true ;;
		-y | --system) add_system_info=true ;;
		*) query+="$1 " ;;
		esac
		shift
	done

	# Handle file reading
	local file_info=""
	if [[ $read_mode == true && -n "$read_file" ]]; then
		file_info=$(extract_file_info "$read_file" $MAX_FILE_CONTENT_LENGTH) || return 1
	fi

	# Handle search operations
	local search_info=""
	if [[ $search_mode == true ]]; then
		search_info=$(perform_search "$search_terms")
	elif [[ $surf_mode == true ]]; then
		search_terms=$(extract_search_terms "$query" "$verbose")
		search_info=$(perform_search "$search_terms")
	fi

	# Configure specific model based on one-off or interactive session
	local quant size repo_name model_name hf_username finetuning filetype
	if [[ -n "$query" ]]; then
		size="$CASUAL_MODEL_SIZE"
		quant="$CASUAL_MODEL_QUANT"
		hf_username="$CASUAL_MODEL_USERNAME"
		series="$CASUAL_MODEL_SERIES"
		finetuning="$CASUAL_MODEL_FINETUNING"
		filetype="$CASUAL_MODEL_FILETYPE"
		interactive=false
	else
		size="$SERIOUS_MODEL_SIZE"
		quant="$SERIOUS_MODEL_QUANT"
		hf_username="$SERIOUS_MODEL_USERNAME"
		series="$SERIOUS_MODEL_SERIES"
		finetuning="$SERIOUS_MODEL_FINETUNING"
		filetype="$SERIOUS_MODEL_FILETYPE"
		interactive=true
	fi
	repo_name="$(compose_repo_name $hf_username $series $size $finetuning $filetype)"
	model_name="$(compose_model_name $series $size $finetuning $quant $filetype)"

	# Generate and start appropriate session
	local prompt
	prompt=$(generate_prompt $interactive "$file_info" "$read_file" "$query" "$search_info" "$search_terms" $add_system_info)
	start_llama_session "$repo_name" "$model_name" "$prompt" $interactive $verbose $verbose 256

}
